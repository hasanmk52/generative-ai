spring.application.name = generativeai
server.servlet.context-path = /generative-ai
server.port = 8080

logging.level.org.springframework.ai.chat.client.advisor = DEBUG

#Disable the ChatClient.Builder autoconfiguration as we want to be able to use multiple LLM's, this is true by default
spring.ai.chat.client.enabled=false

#required below base url if using deepseek model which is compatible with spring open ai
#spring.ai.openai.base-url = https://api.deepseek.com
#use openai key or deepseek api key depending on which model we are using
spring.ai.openai.api-key = ${OPEN_API_KEY}
#can use openai gpt-4o model or deepseek-chat if using deepseek api as base url and deepseek api key
spring.ai.openai.chat.options.model = gpt-4o
#spring.ai.openai.chat.options.model = deepseek-chat
#spring.ai.openai.chat.options.response-format.type = json_object

spring.ai.ollama.base-url = http://localhost:11434
#can also use deepseek-r1:7b model using ollama if running the model locally
spring.ai.ollama.chat.options.model = llama3.2:latest
spring.ai.ollama.chat.options.temperature = 0.8
spring.ai.ollama.chat.options.format = json
spring.ai.ollama.embedding.model = nomic-embed-text

#if using anthropic api model
spring.ai.anthropic.api-key = ${ANTHROPIC_API_KEY}
spring.ai.anthropic.chat.options.model=claude-3-7-sonnet-latest

#https://www.weatherapi.com
spring.weather.api.base.uri = https://api.weatherapi.com/v1 
spring.weather.api.key = abcdefgh